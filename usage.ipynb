{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16861,"status":"ok","timestamp":1648046394601,"user":{"displayName":"김형진","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05530574334109307920"},"user_tz":-540},"id":"TAtrzndb7Vun","outputId":"3446ff4e-31a9-4e4e-b031-e3029464d387"},"outputs":[],"source":["import tensorflow as tf\n","\n","import ssl\n","ssl._create_default_https_context = ssl._create_unverified_context\n","\n","def pipe(data, batch_size = 128, shuffle = False):\n","    dataset = tf.data.Dataset.from_tensor_slices(data)\n","    if shuffle:\n","        dataset = dataset.shuffle(buffer_size = batch_size * 10)\n","    dataset = dataset.batch(batch_size)\n","    #dataset = dataset.prefetch((batch_size * 2) + 1)\n","    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n","    return dataset\n","\n","(tr_x, tr_y), (te_x, te_y) = tf.keras.datasets.cifar10.load_data()\n","\n","tr_x = tr_x * 1/255\n","te_x = te_x * 1/255\n","\n","batch_size = 128\n","\n","tr_data = pipe((tr_x, tr_y), batch_size = batch_size, shuffle = True)\n","te_data = pipe((te_x, te_y), batch_size = batch_size, shuffle = False)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":2979,"status":"ok","timestamp":1648046421518,"user":{"displayName":"김형진","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05530574334109307920"},"user_tz":-540},"id":"ySaeM_5H7Q8A"},"outputs":[{"ename":"TypeError","evalue":"Exception encountered when calling ConvTransformer.call().\n\n\u001b[1mLayer.add_weight() got multiple values for argument 'shape'\u001b[0m\n\nArguments received by ConvTransformer.call():\n  • args=('<KerasTensor shape=(None, 4, 4, 192), dtype=float32, sparse=False, name=keras_tensor_186>',)\n  • kwargs=<class 'inspect._empty'>","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcoatnet\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcoatnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoatnet0\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m'''flatten = tf.keras.layers.GlobalAveragePooling2D()(model.output)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03mdrop_out = tf.keras.layers.Dropout(0.5)(flatten)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03mdense = tf.keras.layers.Dense(2048, activation = \"relu\")(drop_out)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03mprediction = tf.keras.layers.Dense(10, activation = \"softmax\", name = \"prediction\")(dense)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03mmodel = tf.keras.Model(model.input, prediction)'''\u001b[39;00m\n","File \u001b[0;32m~/VSCode/audioSideChannelAttack/coatnet/coatnet.py:265\u001b[0m, in \u001b[0;36mcoatnet0\u001b[0;34m(input_tensor, input_shape, classes, include_top, weights)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m         img_input \u001b[38;5;241m=\u001b[39m input_tensor\n\u001b[0;32m--> 265\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mcoatnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_depth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_feature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m192\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m384\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m768\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage_stride_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_ratio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mse_ratio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgelu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(img_input, out)\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m~/VSCode/audioSideChannelAttack/coatnet/coatnet.py:247\u001b[0m, in \u001b[0;36mcoatnet\u001b[0;34m(x, n_class, include_top, n_depth, n_feature, block, stage_stride_size, expand_ratio, se_ratio, dropout_rate, activation, name)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m _block\u001b[38;5;241m.\u001b[39mupper() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    246\u001b[0m             out \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLayerNormalization(epsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-5\u001b[39m, name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m_pre_norm\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, i, j \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))(out)\n\u001b[0;32m--> 247\u001b[0m             out \u001b[38;5;241m=\u001b[39m \u001b[43mConvTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstride_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_n_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{0}\u001b[39;49;00m\u001b[38;5;124;43mstage\u001b[39;49m\u001b[38;5;132;43;01m{1}\u001b[39;49;00m\u001b[38;5;124;43m_transformer\u001b[39;49m\u001b[38;5;132;43;01m{2}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_top:\n\u001b[1;32m    250\u001b[0m     out \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mGlobalAveragePooling2D(name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124mgap\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name))(out)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m~/VSCode/audioSideChannelAttack/coatnet/coatnet.py:207\u001b[0m, in \u001b[0;36mConvTransformer.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    205\u001b[0m out \u001b[38;5;241m=\u001b[39m inputs\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention:\n\u001b[0;32m--> 207\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresidual:\n\u001b[1;32m    209\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m layer(inputs)\n","File \u001b[0;32m~/VSCode/audioSideChannelAttack/coatnet/coatnet.py:103\u001b[0m, in \u001b[0;36mMultiHeadSelfAttention.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_shape):\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_window_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_position_bias_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelative_position_bias_table\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelative_window_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelative_window_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_head\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m         coords_h \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_window_size[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    105\u001b[0m         coords_w \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_window_size[\u001b[38;5;241m1\u001b[39m])\n","\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling ConvTransformer.call().\n\n\u001b[1mLayer.add_weight() got multiple values for argument 'shape'\u001b[0m\n\nArguments received by ConvTransformer.call():\n  • args=('<KerasTensor shape=(None, 4, 4, 192), dtype=float32, sparse=False, name=keras_tensor_186>',)\n  • kwargs=<class 'inspect._empty'>"]}],"source":["import coatnet\n","\n","model = coatnet.coatnet0(input_shape = (32, 32, 3), include_top = True)\n","\n","'''flatten = tf.keras.layers.GlobalAveragePooling2D()(model.output)\n","drop_out = tf.keras.layers.Dropout(0.5)(flatten)\n","dense = tf.keras.layers.Dense(2048, activation = \"relu\")(drop_out)\n","prediction = tf.keras.layers.Dense(10, activation = \"softmax\", name = \"prediction\")(dense)\n","model = tf.keras.Model(model.input, prediction)'''"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":258,"status":"ok","timestamp":1648046425716,"user":{"displayName":"김형진","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05530574334109307920"},"user_tz":-540},"id":"cka3vwta8pmU"},"outputs":[],"source":["loss = tf.keras.losses.sparse_categorical_crossentropy\n","opt = tf.keras.optimizers.Adam(1e-4)\n","metric = [tf.keras.metrics.sparse_categorical_accuracy]\n","model.compile(loss = loss, optimizer = opt, metrics = metric)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":891556,"status":"ok","timestamp":1648047318401,"user":{"displayName":"김형진","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05530574334109307920"},"user_tz":-540},"id":"S2T8gk6z9iBH","outputId":"7766a3ba-f479-4d52-ba4b-a3db6f775be9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","391/391 [==============================] - 122s 232ms/step - loss: 1.9192 - sparse_categorical_accuracy: 0.2442 - val_loss: 1.8568 - val_sparse_categorical_accuracy: 0.2575\n","Epoch 2/10\n","391/391 [==============================] - 81s 207ms/step - loss: 1.8239 - sparse_categorical_accuracy: 0.2806 - val_loss: 1.7438 - val_sparse_categorical_accuracy: 0.3051\n","Epoch 3/10\n","391/391 [==============================] - 81s 206ms/step - loss: 1.6805 - sparse_categorical_accuracy: 0.3433 - val_loss: 1.6522 - val_sparse_categorical_accuracy: 0.3601\n","Epoch 4/10\n","391/391 [==============================] - 81s 207ms/step - loss: 1.6476 - sparse_categorical_accuracy: 0.3630 - val_loss: 1.6518 - val_sparse_categorical_accuracy: 0.3702\n","Epoch 5/10\n","391/391 [==============================] - 80s 206ms/step - loss: 1.6377 - sparse_categorical_accuracy: 0.3659 - val_loss: 1.6750 - val_sparse_categorical_accuracy: 0.3463\n","Epoch 6/10\n","391/391 [==============================] - 81s 206ms/step - loss: 1.6530 - sparse_categorical_accuracy: 0.3598 - val_loss: 1.5698 - val_sparse_categorical_accuracy: 0.4029\n","Epoch 7/10\n","391/391 [==============================] - 81s 206ms/step - loss: 1.5146 - sparse_categorical_accuracy: 0.4105 - val_loss: 1.5122 - val_sparse_categorical_accuracy: 0.4198\n","Epoch 8/10\n","391/391 [==============================] - 81s 206ms/step - loss: 1.4390 - sparse_categorical_accuracy: 0.4413 - val_loss: 1.4902 - val_sparse_categorical_accuracy: 0.4467\n","Epoch 9/10\n","391/391 [==============================] - 81s 206ms/step - loss: 1.3798 - sparse_categorical_accuracy: 0.4654 - val_loss: 1.4826 - val_sparse_categorical_accuracy: 0.4464\n","Epoch 10/10\n","391/391 [==============================] - 81s 207ms/step - loss: 1.3178 - sparse_categorical_accuracy: 0.4936 - val_loss: 1.4437 - val_sparse_categorical_accuracy: 0.4637\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f65c96a7c50>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(tr_data, validation_data = te_data, epochs = 10)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1072,"status":"ok","timestamp":1648047337558,"user":{"displayName":"김형진","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05530574334109307920"},"user_tz":-540},"id":"tXn4W1lqhbbf"},"outputs":[],"source":["model.save_weights(\"model.h5\")"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":383,"status":"ok","timestamp":1648047340146,"user":{"displayName":"김형진","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05530574334109307920"},"user_tz":-540},"id":"9Rx7ssmeh167"},"outputs":[],"source":["model.load_weights(\"model.h5\")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16103,"status":"ok","timestamp":1648047357154,"user":{"displayName":"김형진","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05530574334109307920"},"user_tz":-540},"id":"JTBoj3vrFLca","outputId":"0e6b0788-7696-4bad-86ba-cad850aaab6c"},"outputs":[{"name":"stdout","output_type":"stream","text":["79/79 [==============================] - 11s 72ms/step - loss: 1.4437 - sparse_categorical_accuracy: 0.4637\n"]},{"data":{"text/plain":["[1.4436622858047485, 0.46369999647140503]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["loss = tf.keras.losses.sparse_categorical_crossentropy\n","metric = [tf.keras.metrics.sparse_categorical_accuracy]\n","model.compile(loss = loss, metrics = metric)\n","model.evaluate(te_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MsTu5aaRHY9d"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"usage.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
